{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPNzUsD7LzKs"
      },
      "source": [
        "<p style=\"text-align:center\">\n",
        "    <a href=\"https://skills.network\" target=\"_blank\">\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
        "    </a>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb5rTGpILzKu"
      },
      "source": [
        "# **Lab: Building Advanced Transformers**\n",
        "\n",
        "**Estimated time needed:  30 minutes**  \n",
        "\n",
        "In this lab, you will implement and experiment with advanced Transformer models using Keras.\n",
        "\n",
        "**Learning objectives:**\n",
        "\n",
        "By the end of this lab, you will:\n",
        "\n",
        "- Implement advanced Transformer models using Keras.\n",
        "\n",
        "- Apply Transformers to real-world sequential data tasks.\n",
        "\n",
        "- Build, train, and evaluate Transformer models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhW7_ZylLzKv"
      },
      "source": [
        "## Step-by-Step Instructions:\n",
        "\n",
        "### Step 1: Import necessary libraries\n",
        "\n",
        "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpM2V-fULzKv",
        "outputId": "d550fc6c-cb08-4f92-ab3c-6e12a233a69a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (17.0.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow pyarrow\n",
        "%pip install pandas\n",
        "%pip install scikit-learn\n",
        "%pip install matplotlib\n",
        "%pip install requests\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vuMxgARhLzKw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBdJOcGULzKx"
      },
      "source": [
        "####  Setup the Environment to generate synthetic stock price data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaSFXZNbLzKx",
        "outputId": "2ac7e846-b636-4fc1-e90f-33ccfd7adb01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic stock_prices.csv created and loaded.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Create a synthetic stock price dataset\n",
        "np.random.seed(42)\n",
        "data_length = 2000  # Adjust data length as needed\n",
        "trend = np.linspace(100, 200, data_length)\n",
        "noise = np.random.normal(0, 2, data_length)\n",
        "synthetic_data = trend + noise\n",
        "\n",
        "# Create a DataFrame and save as 'stock_prices.csv'\n",
        "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
        "data.to_csv('stock_prices.csv', index=False)\n",
        "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6zQ0-7WLzKx",
        "outputId": "47f631c1-f2ae-430a-dfaa-06944254856f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (1899, 100, 1)\n",
            "Shape of Y: (1899,)\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('stock_prices.csv')\n",
        "data = data[['Close']].values\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data = scaler.fit_transform(data)\n",
        "\n",
        "# Prepare the data for training\n",
        "def create_dataset(data, time_step=1):\n",
        "    X, Y = [], []\n",
        "\n",
        "    for i in range(len(data)-time_step-1):\n",
        "        a = data[i:(i+time_step), 0]\n",
        "        X.append(a)\n",
        "        Y.append(data[i + time_step, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "time_step = 100\n",
        "X, Y = create_dataset(data, time_step)\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of Y:\", Y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbMFBgXuLzKx"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "`tensorflow` is the main library for machine learning in Python.  \n",
        "\n",
        "`stock_prices.csv` is the data set that is loaded.\n",
        "\n",
        "`MinMaxScaler` method is used to normalize the data.  \n",
        "\n",
        "`create_dataset`method is used to prepare the data for training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLlUPfj3LzKy"
      },
      "source": [
        "### Step 2: Implement Multi-Head Self-Attention\n",
        "\n",
        "Define the Multi-Head Self-Attention mechanism.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d5LET3nLLzKy"
      },
      "outputs": [],
      "source": [
        "class MultiHeadSelfAttention(Layer):\n",
        "\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = Dense(embed_dim)\n",
        "        self.key_dense = Dense(embed_dim)\n",
        "        self.value_dense = Dense(embed_dim)\n",
        "        self.combine_heads = Dense(embed_dim)\n",
        "\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "        attention, _ = self.attention(query, key, value)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
        "        output = self.combine_heads(concat_attention)\n",
        "        return output\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7TcHrs3LzKy"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously.\n",
        "\n",
        "- The attention parameter computes the attention scores and weighted sum of the values.\n",
        "\n",
        "- The split_heads parameter splits the input into multiple heads for parallel attention computation.\n",
        "\n",
        "- The call method applies the self-attention mechanism and combines the heads.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMh7ld_8LzKy"
      },
      "source": [
        "### Step 3: Implement Transformer block\n",
        "\n",
        "Define the Transformer block.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LIVaQGuHLzKy"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(Layer):\n",
        "\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py4E1sXdLzKz"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
        "\n",
        "- Dropout is used to prevent overfitting.\n",
        "\n",
        "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtnU-TkMLzKz"
      },
      "source": [
        "### Step 4: Implement Encoder Layer\n",
        "\n",
        "Define the Encoder layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "K0ls9yEzLzKz"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(Layer):\n",
        "\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1yy8OKuLzKz"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture.\n",
        "\n",
        "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network.\n",
        "\n",
        "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer.\n",
        "\n",
        "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiN-8W1fLzKz"
      },
      "source": [
        "### Step 5: Implement Transformer encoder\n",
        "\n",
        "Define the Transformer Encoder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAc6fa6YLzKz",
        "outputId": "f2908b1c-d7c0-448d-a166-1d0d7e124618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'transformer_encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 100, 128)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout\n",
        "\n",
        "class MultiHeadSelfAttention(Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = Dense(embed_dim)\n",
        "        self.key_dense = Dense(embed_dim)\n",
        "        self.value_dense = Dense(embed_dim)\n",
        "        self.combine_heads = Dense(embed_dim)\n",
        "\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "        attention, _ = self.attention(query, key, value)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
        "        output = self.combine_heads(concat_attention)\n",
        "        return output\n",
        "\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class TransformerEncoder(Layer):\n",
        "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.embed_dim = embed_dim\n",
        "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)]\n",
        "        self.dropout = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = inputs\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training=training)\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "embed_dim = 128\n",
        "num_heads = 8\n",
        "ff_dim = 512\n",
        "num_layers = 4\n",
        "\n",
        "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim)\n",
        "inputs = tf.random.uniform((1, 100, embed_dim))\n",
        "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training'\n",
        "print(outputs.shape)  # Should print (1, 100, 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIsHJigvLzK0"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9GkPYAwLzK0"
      },
      "source": [
        "### Step 6: Build and Compile the Transformer model\n",
        "\n",
        "Integrate the Transformer Encoder into a complete model for sequential data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "FEVANgADLzK0",
        "outputId": "92c3f89d-2e33-42c3-a5ab-69170a21168f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'transformer_encoder_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m793,088\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │          \u001b[38;5;34m12,801\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Define the necessary parameters\n",
        "\n",
        "embed_dim = 128\n",
        "num_heads = 8\n",
        "ff_dim = 512\n",
        "num_layers = 4\n",
        "\n",
        "# Define the Transformer Encoder\n",
        "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim)\n",
        "\n",
        "# Build the model\n",
        "input_shape = (X.shape[1], X.shape[2])\n",
        "inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "# Project the inputs to the embed_dim\n",
        "x = tf.keras.layers.Dense(embed_dim)(inputs)\n",
        "encoder_outputs = transformer_encoder(x)\n",
        "flatten = tf.keras.layers.Flatten()(encoder_outputs)\n",
        "outputs = tf.keras.layers.Dense(1)(flatten)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3nNHXxELzK0"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
        "\n",
        "- The model is then compiled with the Adam optimizer and mean squared error loss.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX1WI94lLzK0"
      },
      "source": [
        "### Step 7: Train the Transformer model\n",
        "\n",
        "Train the model on the prepared dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1lqq673LzK0",
        "outputId": "246ed57a-e801-4cfb-f3ce-45c309bcb6a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 222ms/step - loss: 12.6197\n",
            "Epoch 2/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1870\n",
            "Epoch 3/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.2241\n",
            "Epoch 4/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1802\n",
            "Epoch 5/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1732\n",
            "Epoch 6/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1701\n",
            "Epoch 7/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1958\n",
            "Epoch 8/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1118\n",
            "Epoch 9/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1087\n",
            "Epoch 10/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1235\n",
            "Epoch 11/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1131\n",
            "Epoch 12/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1346\n",
            "Epoch 13/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0819\n",
            "Epoch 14/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0799\n",
            "Epoch 15/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1375\n",
            "Epoch 16/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0578\n",
            "Epoch 17/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0442\n",
            "Epoch 18/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0525\n",
            "Epoch 19/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0380\n",
            "Epoch 20/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0322\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a10e69a4160>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0KuvW_DLzK1"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BztAQwGVLzK1"
      },
      "source": [
        "### Step 8: Evaluate and Make Predictions\n",
        "\n",
        "Evaluate the model's performance and make predictions on the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "qNMGLsCqLzK1",
        "outputId": "3320e109-4fff-4127-fff4-e019f5b85c3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(X)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "\n",
        "# Plot the predictions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(data, label='True Data')\n",
        "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvM3oF8FLzK1"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler.\n",
        "\n",
        "- The true data and predictions are plotted to visualize the model's performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gthWLLuoLzK1"
      },
      "source": [
        "## Practice Exercises:\n",
        "\n",
        " ### Exercise 1: Add dropout to the Transformer model\n",
        "\n",
        " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.**\n",
        "\n",
        " Instructions:\n",
        "\n",
        "- Add a dropout layer after the Flatten layer in the model.\n",
        "\n",
        "- Set the dropout rate to 0.5.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZPogkDXLzK1",
        "outputId": "2fcd9e54-d5f0-4bbf-a919-4eccdb7f6c5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 232ms/step - loss: 5.9581\n",
            "Epoch 2/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.9275\n",
            "Epoch 3/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.5042\n",
            "Epoch 4/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1363\n",
            "Epoch 5/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0749\n",
            "Epoch 6/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0592\n",
            "Epoch 7/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0567\n",
            "Epoch 8/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0468\n",
            "Epoch 9/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0431\n",
            "Epoch 10/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0373\n",
            "Epoch 11/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0352\n",
            "Epoch 12/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0321\n",
            "Epoch 13/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0282\n",
            "Epoch 14/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0256\n",
            "Epoch 15/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0256\n",
            "Epoch 16/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0271\n",
            "Epoch 17/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0272\n",
            "Epoch 18/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0241\n",
            "Epoch 19/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0231\n",
            "Epoch 20/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0252\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0039\n",
            "Test loss: 0.0039571127854287624\n"
          ]
        }
      ],
      "source": [
        "## Write your code here.\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# Add a dropout layer after the Flatten layer\n",
        "flatten = tf.keras.layers.Flatten()(encoder_outputs)\n",
        "dropout = Dropout(0.5)(flatten)\n",
        "outputs = tf.keras.layers.Dense(1)(dropout)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f\"Test loss: {loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR7noe09LzK2"
      },
      "source": [
        "<details><summary>Click here to view the solution.</summary>\n",
        "\n",
        "```\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "  \n",
        "\n",
        "# Add a dropout layer after the Flatten layer\n",
        "\n",
        "flatten = tf.keras.layers.Flatten()(encoder_outputs)\n",
        "\n",
        "dropout = Dropout(0.5)(flatten)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(1)(dropout)\n",
        "\n",
        "  \n",
        "\n",
        "# Build the model\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "  \n",
        "\n",
        "# Compile the model\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "  \n",
        "\n",
        "# Train the model\n",
        "\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n",
        "\n",
        "  \n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "loss = model.evaluate(X, Y)\n",
        "\n",
        "print(f'Test loss: {loss}')\n",
        "\n",
        "```\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUj21_eNLzK2"
      },
      "source": [
        "### Exercise 2: Experiment with different batch sizes\n",
        "\n",
        "**Objective: Observe the impact of different batch sizes on model performance.**\n",
        "\n",
        " Instructions:\n",
        "\n",
        "- Train the model with a batch size of 16.\n",
        "\n",
        "- Train the model with a batch size of 64.\n",
        "\n",
        "- Compare the training time and performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an0TwdbeLzK2",
        "outputId": "62c8916c-da4c-4d27-cd70-a7683677f5a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0255\n",
            "Epoch 2/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0653\n",
            "Epoch 3/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0642\n",
            "Epoch 4/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0408\n",
            "Epoch 5/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0305\n",
            "Epoch 6/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0235\n",
            "Epoch 7/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0155\n",
            "Epoch 8/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0156\n",
            "Epoch 9/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0199\n",
            "Epoch 10/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0150\n",
            "Epoch 11/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0184\n",
            "Epoch 12/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0238\n",
            "Epoch 13/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0140\n",
            "Epoch 14/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0146\n",
            "Epoch 15/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0125\n",
            "Epoch 16/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0227\n",
            "Epoch 17/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0113\n",
            "Epoch 18/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0119\n",
            "Epoch 19/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0118\n",
            "Epoch 20/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0108\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074\n",
            "Test loss with batch size 16: 0.0034857382997870445\n",
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 445ms/step - loss: 0.0072\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - loss: 0.0036\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0030\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0039\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0026\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0027\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0022\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0026\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0026\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0024\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0025\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0029\n",
            "Epoch 13/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0025\n",
            "Epoch 14/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0028\n",
            "Epoch 15/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0034\n",
            "Epoch 16/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0022\n",
            "Epoch 17/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0039\n",
            "Epoch 18/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0049\n",
            "Epoch 19/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0025\n",
            "Epoch 20/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0021\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017\n",
            "Test loss with batch size 64: 0.0012994110584259033\n"
          ]
        }
      ],
      "source": [
        "## Write your code here.\n",
        "\n",
        "# Train the model with batch size 16\n",
        "model.fit(X, Y, epochs=20, batch_size=16)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f\"Test loss with batch size 16: {loss}\")\n",
        "\n",
        "# Train the model with batch size 64\n",
        "model.fit(X, Y, epochs=20, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f\"Test loss with batch size 64: {loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xUuSjV4LzK2"
      },
      "source": [
        "<details><summary>Click here to view the solution.</summary>\n",
        "\n",
        "```\n",
        "# Train the model with batch size 16\n",
        "model.fit(X, Y, epochs=20, batch_size=16)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with batch size 16: {loss}')\n",
        "\n",
        "# Train the model with batch size 64\n",
        "model.fit(X, Y, epochs=20, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with batch size 64: {loss}')\n",
        "\n",
        "```\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLjkn0cFLzK2"
      },
      "source": [
        "### Exercise 3: Use a different activation function\n",
        "\n",
        " **Objective: Understand how different activation functions impact the model performance.**\n",
        "\n",
        " Instructions:\n",
        "\n",
        "- Change the activation function of the Dense layer to `tanh`.\n",
        "\n",
        "- Train and evaluate the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6xWoc8wLzK2",
        "outputId": "82b60bdf-efb0-4a9a-9f5d-c6c2315c7ae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 224ms/step - loss: 0.2140\n",
            "Epoch 2/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0411\n",
            "Epoch 3/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0058\n",
            "Epoch 4/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0027\n",
            "Epoch 5/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0034\n",
            "Epoch 6/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0019\n",
            "Epoch 7/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0028\n",
            "Epoch 8/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0038\n",
            "Epoch 9/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0015\n",
            "Epoch 10/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0032\n",
            "Epoch 11/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0022\n",
            "Epoch 12/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0017\n",
            "Epoch 13/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0014\n",
            "Epoch 14/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0015\n",
            "Epoch 15/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0026\n",
            "Epoch 16/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0018\n",
            "Epoch 17/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0024\n",
            "Epoch 18/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0025\n",
            "Epoch 19/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0015\n",
            "Epoch 20/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0020\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.0019\n",
            "Test loss with tanh activation: 0.0013662164565175772\n"
          ]
        }
      ],
      "source": [
        "## Write your code here.\n",
        "\n",
        "# Change the activation function of the Dense layer to tanh\n",
        "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f\"Test loss with tanh activation: {loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4f0K2ZvLzK3"
      },
      "source": [
        "<details><summary>Click here to view the solution.</summary>\n",
        "\n",
        "```\n",
        "# Change the activation function of the Dense layer to tanh\n",
        "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with tanh activation: {loss}')\n",
        "\n",
        "```\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiRY07xSLzK3"
      },
      "source": [
        "## Conclusion\n",
        "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM0FZMhHLzK3"
      },
      "source": [
        "Copyright © IBM Corporation. All rights reserved.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "prev_pub_hash": "28ac4fd81c1d713f83dcd1cdf1d3383ad25ea92873288fe9e978e9a17b314709",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}